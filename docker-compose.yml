services:
  yue-exllamav2-interface:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: yue-exllamav2-interface
    restart: unless-stopped
    ports:
      - "7860:7860"  # Gradio UI
      - "8888:8888"  # JupyterLab
    environment:
      # Model selection - set in .env file or override here
      # Options: all_bf16, all_exl2, all, false, or comma-separated list
      # Recommended for 16GB VRAM: YuE-s1-7B-anneal-en-cot-exl2-4.0bpw,YuE-s2-1B-general-exl2-6.0bpw,YuE-upsampler
      - DOWNLOAD_MODELS=${DOWNLOAD_MODELS:-YuE-s1-7B-anneal-en-cot-exl2-4.0bpw,YuE-s2-1B-general-exl2-6.0bpw,YuE-upsampler}
      - HF_TOKEN=${HF_TOKEN:-}
      - NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES:-all}
    volumes:
      - ${WORKSPACE_DIR:-./workspace}/models:/workspace/models
      - ${WORKSPACE_DIR:-./workspace}/outputs:/workspace/outputs
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Enable GPU support (requires NVIDIA GPU and drivers)